# Classificador de Fake News com MLP e Naive Bayes

Este projeto implementa classificadores de fake news usando MLP (Multi-Layer Perceptron) e Naive Bayes em Go. O sistema analisa textos de not√≠cias e classifica se s√£o provavelmente verdadeiras ou falsas, com suporte a compara√ß√£o entre algoritmos em uma URL espec√≠fica.

## Estrutura do Projeto

```
ml-nb-model/
‚îú‚îÄ‚îÄ cmd/
‚îÇ   ‚îî‚îÄ‚îÄ classifier/
‚îÇ       ‚îî‚îÄ‚îÄ main.go              # Ponto de entrada principal
‚îú‚îÄ‚îÄ internal/
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ types.go             # Estruturas de dados
‚îÇ   ‚îú‚îÄ‚îÄ utils/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ text_processing.go   # Processamento de texto
‚îÇ   ‚îú‚îÄ‚îÄ crawler/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ web_crawler.go       # Web scraping
‚îÇ   ‚îú‚îÄ‚îÄ mlp/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ classifier.go        # Classificador MLP
‚îÇ   ‚îî‚îÄ‚îÄ naivebayes/
‚îÇ       ‚îî‚îÄ‚îÄ classifier.go        # Classificador Naive Bayes
‚îú‚îÄ‚îÄ test_urls_analysis.go        # Teste das 5 URLs especificadas
‚îú‚îÄ‚îÄ main.go                      # Arquivo original (legado)
‚îú‚îÄ‚îÄ go.mod                       # Depend√™ncias do projeto
‚îî‚îÄ‚îÄ README.md                    # Este arquivo
```

## Caracter√≠sticas

- **Dois Algoritmos**: MLP (rede neural) e Naive Bayes
- **Compara√ß√£o em Tempo Real**: Analisa uma URL com ambos os algoritmos
- **M√©tricas Detalhadas**: Confian√ßa, probabilidades e tokens influentes
- **Processamento de Texto**: Tokeniza√ß√£o e remo√ß√£o de stop words em portugu√™s
- **Vocabul√°rio Din√¢mico**: Constru√≠do automaticamente a partir dos dados de treinamento
- **Web Scraping**: Extra√ß√£o autom√°tica de conte√∫do de URLs de not√≠cias
- **Classifica√ß√£o Bin√°ria**: Verdadeira vs Falsa
- **Arquitetura Modular**: Separa√ß√£o clara de responsabilidades

## Arquitetura dos Algoritmos

### MLP (Multi-Layer Perceptron)
```
Entrada (1000) ‚Üí Camada Oculta (50) ‚Üí Sa√≠da (2)
```

- **Camada de Entrada**: 1000 neur√¥nios (tamanho do vocabul√°rio)
- **Camada Oculta**: 50 neur√¥nios com fun√ß√£o de ativa√ß√£o sigmoid
- **Camada de Sa√≠da**: 2 neur√¥nios (verdadeira/falsa) com fun√ß√£o de ativa√ß√£o sigmoid

### Naive Bayes
- **Probabil√≠stico**: Baseado em teorema de Bayes
- **Suaviza√ß√£o de Laplace**: Para lidar com palavras n√£o vistas
- **Log-probabilidades**: Para estabilidade num√©rica

## Par√¢metros de Treinamento

### MLP
- **Learning Rate**: 0.01
- **√âpocas**: 100 (padr√£o) / 10 (cross-validation)
- **Fun√ß√£o de Ativa√ß√£o**: Sigmoid
- **Fun√ß√£o de Perda**: Mean Squared Error (MSE)

### Naive Bayes
- **Suaviza√ß√£o**: Laplace (Œ± = 1)
- **Vocabul√°rio**: Todas as palavras √∫nicas
- **Stop Words**: Removidas automaticamente

## Como Usar

### Compila√ß√£o

```bash
# Compilar o classificador principal
go build -o classifier cmd/classifier/main.go

# Compilar o teste das URLs
go build -o test_analysis test_urls_analysis.go
```

### Execu√ß√£o

#### 1. Compara√ß√£o de Algoritmos (Padr√£o - com Cross-Validation)
```bash
./classifier <URL_da_noticia>
```
ou
```bash
go run cmd/classifier/main.go <URL_da_noticia>
```

**Sa√≠da esperada:**
```
========================================================================================================================
COMPARA√á√ÉO ENTRE ALGORITMOS
========================================================================================================================
URL analisada: https://exemplo.com/noticia

Algoritmo           Classifica√ß√£o           Confian√ßa        Probabilidades      Acur√°cia     Precis√£o     Revoca√ß√£o    F1-Score
------------------------------------------------------------------------------------------------------------------------
MLP                 Provavelmente Verdadeira 85.32%         V:85.3% F:14.7%     0.8500       0.8600       0.8400       0.8500
Naive Bayes         Provavelmente Verdadeira 82.15%         V:82.2% F:17.8%     0.8200       0.8300       0.8100       0.8200
========================================================================================================================

=== COMPARA√á√ÉO DE PERFORMANCE GERAL ===
MLP vs Naive Bayes:
  Acur√°cia:   0.8500 vs 0.8200 (diferen√ßa: 0.0300)
  Precis√£o:   0.8600 vs 0.8300 (diferen√ßa: 0.0300)
  Revoca√ß√£o:  0.8400 vs 0.8100 (diferen√ßa: 0.0300)
  F1-Score:   0.8500 vs 0.8200 (diferen√ßa: 0.0300)
========================================================================================================================
```

#### 2. Compara√ß√£o R√°pida (Sem Cross-Validation)
```bash
./classifier fast <URL_da_noticia>
```
ou
```bash
go run cmd/classifier/main.go fast <URL_da_noticia>
```

**Sa√≠da esperada:**
```
================================================================================
COMPARA√á√ÉO ENTRE ALGORITMOS (VERS√ÉO R√ÅPIDA)
================================================================================
URL analisada: https://exemplo.com/noticia

Algoritmo           Classifica√ß√£o           Confian√ßa        Probabilidades
--------------------------------------------------------------------------------
MLP                 Provavelmente Verdadeira 85.32%         V:85.3% F:14.7%
Naive Bayes         Provavelmente Verdadeira 82.15%         V:82.2% F:17.8%
================================================================================

=== TOKENS MAIS INFLUENTES ===
MLP:
  palavra1 (1.00)
  palavra2 (1.00)
  ...

Naive Bayes:
  palavra1 (-2.34)
  palavra2 (-1.87)
  ...

=== AN√ÅLISE DE CONCORD√ÇNCIA ===
‚úÖ Os algoritmos concordam: Provavelmente Verdadeira

Diferen√ßa de confian√ßa: 3.17%
üìä Baixa diverg√™ncia entre os algoritmos
================================================================================
```

#### 3. Classifica√ß√£o com MLP Apenas
```bash
./classifier mlp <URL_da_noticia>
```
ou
```bash
go run cmd/classifier/main.go mlp <URL_da_noticia>
```

#### 4. Classifica√ß√£o com Naive Bayes Apenas
```bash
./classifier nb <URL_da_noticia>
```
ou
```bash
go run cmd/classifier/main.go nb <URL_da_noticia>
```

### Exemplos de Uso

```bash
# Compara√ß√£o completa com cross-validation (mais lento)
./classifier https://g1.globo.com/noticia-exemplo

# Compara√ß√£o r√°pida sem cross-validation
./classifier fast https://g1.globo.com/noticia-exemplo

# Usar apenas MLP
./classifier mlp https://g1.globo.com/noticia-exemplo

# Usar apenas Naive Bayes
./classifier nb https://g1.globo.com/noticia-exemplo
```

## Teste das 5 URLs Especificadas

Para testar as 5 URLs especificadas:

```bash
# Executar o teste
./test_analysis

# Ou executar diretamente
go run test_urls_analysis.go
```

**URLs testadas:**
1. **G1 - Sa√∫de**: Higiene do sono
2. **G1 - Pol√≠tica**: Den√∫ncia MPMG sobre drone
3. **Boatos.org - Pol√≠tica**: Boato sobre Haddad e imposto do oxig√™nio
4. **Estad√£o - Verifica√ß√£o**: Contas dark no Instagram
5. **Boatos.org - Pol√≠tica**: Boato sobre porta-avi√µes no Lago Parano√°

## Sa√≠da de Compara√ß√£o

O sistema fornece informa√ß√µes detalhadas sobre a classifica√ß√£o de ambos os algoritmos:

### Tabela de Resultados (Vers√£o Completa)
- **Algoritmo**: MLP ou Naive Bayes
- **Classifica√ß√£o**: "Provavelmente Verdadeira" ou "Provavelmente Falsa"
- **Confian√ßa**: Percentual de confian√ßa da classifica√ß√£o
- **Probabilidades**: Probabilidades para cada classe (Verdadeira/Falsa)
- **Acur√°cia**: Taxa de acertos gerais (5-fold cross-validation)
- **Precis√£o**: Taxa de verdadeiros positivos entre os preditos como positivos
- **Revoca√ß√£o**: Taxa de verdadeiros positivos entre os reais positivos
- **F1-Score**: M√©dia harm√¥nica entre precis√£o e revoca√ß√£o

### Tabela de Resultados (Vers√£o R√°pida)
- **Algoritmo**: MLP ou Naive Bayes
- **Classifica√ß√£o**: "Provavelmente Verdadeira" ou "Provavelmente Falsa"
- **Confian√ßa**: Percentual de confian√ßa da classifica√ß√£o
- **Probabilidades**: Probabilidades para cada classe (Verdadeira/Falsa)

### Tokens Mais Influentes
- **MLP**: Palavras com maior peso no vetor de entrada (valores positivos)
- **Naive Bayes**: Palavras com maior contribui√ß√£o logar√≠tmica (valores negativos = mais falsas)

### An√°lise de Concord√¢ncia
- **‚úÖ Concord√¢ncia**: Ambos os algoritmos chegam √† mesma conclus√£o
- **‚ùå Discord√¢ncia**: Algoritmos chegam a conclus√µes diferentes
- **Diferen√ßa de Confian√ßa**: Medida da diverg√™ncia entre os algoritmos

### N√≠veis de Diverg√™ncia
- **Baixa**: < 10% de diferen√ßa
- **Moderada**: 10-25% de diferen√ßa
- **Alta**: > 25% de diferen√ßa

### Compara√ß√£o de Performance Geral (Vers√£o Completa)
- **Acur√°cia**: Compara√ß√£o direta entre os algoritmos
- **Precis√£o**: Qualidade das predi√ß√µes positivas
- **Revoca√ß√£o**: Capacidade de encontrar todos os positivos
- **F1-Score**: Balanceamento entre precis√£o e revoca√ß√£o

## Dataset

O sistema utiliza o dataset FakeTrue.Br, que cont√©m pares de not√≠cias verdadeiras e falsas em portugu√™s brasileiro. O dataset √© baixado automaticamente durante a execu√ß√£o.

## Processamento de Texto

1. **Tokeniza√ß√£o**: Divis√£o do texto em palavras
2. **Normaliza√ß√£o**: Convers√£o para min√∫sculas
3. **Limpeza**: Remo√ß√£o de pontua√ß√£o e caracteres especiais
4. **Filtragem**: Remo√ß√£o de stop words em portugu√™s
5. **Vectoriza√ß√£o**: Convers√£o para vetor de entrada (MLP) ou contagem de palavras (NB)

## Compara√ß√£o entre Algoritmos

### Vantagens do MLP:
1. **Capacidade de Aprendizado N√£o-Linear**: Pode capturar rela√ß√µes complexas entre palavras
2. **Representa√ß√£o Distribu√≠da**: Palavras similares podem ter representa√ß√µes similares
3. **Flexibilidade**: Pode ser facilmente expandido com mais camadas ou neur√¥nios

### Vantagens do Naive Bayes:
1. **Velocidade**: Treinamento e classifica√ß√£o muito r√°pidos
2. **Interpretabilidade**: F√°cil de entender como as decis√µes s√£o tomadas
3. **Efici√™ncia**: Requer menos dados para treinamento
4. **Estabilidade**: Menos propenso a overfitting

## Estrutura do C√≥digo

### M√≥dulos Principais:
- `cmd/classifier/main.go`: Ponto de entrada principal
- `internal/models/types.go`: Estruturas de dados
- `internal/utils/text_processing.go`: Processamento de texto
- `internal/crawler/web_crawler.go`: Web scraping
- `internal/mlp/classifier.go`: Classificador MLP
- `internal/naivebayes/classifier.go`: Classificador Naive Bayes

### Fun√ß√µes Principais:
- `compareAlgorithms`: Compara√ß√£o completa com cross-validation
- `compareAlgorithmsFast`: Compara√ß√£o r√°pida sem cross-validation
- `classifyNews`: Classifica√ß√£o com algoritmo espec√≠fico
- `evaluateModel`: Avalia√ß√£o com cross-validation
- `analyzeURLTest`: An√°lise de URL espec√≠fica (teste)

## Depend√™ncias

- `github.com/PuerkitoBio/goquery`: Para web scraping
- Bibliotecas padr√£o do Go: `math`, `math/rand`, `strings`, `regexp`, etc.

## Limita√ß√µes

1. **Vocabul√°rio Fixo**: MLP limitado a 1000 palavras mais frequentes
2. **Arquitetura Simples**: MLP com apenas uma camada oculta
3. **Tempo de Processamento**: MLP requer mais tempo que Naive Bayes
4. **Mem√≥ria**: MLP requer mais mem√≥ria que Naive Bayes

## Poss√≠veis Melhorias

1. **Embeddings**: Usar word embeddings ao inv√©s de one-hot encoding
2. **Arquitetura Mais Profunda**: Adicionar mais camadas ocultas ao MLP
3. **Dropout**: Implementar dropout para regulariza√ß√£o
4. **Batch Training**: Treinar em lotes para melhor performance
5. **Early Stopping**: Parar treinamento quando erro n√£o diminui
6. **Hiperpar√¢metros**: Otimiza√ß√£o autom√°tica de hiperpar√¢metros
7. **Ensemble Methods**: Combina√ß√£o dos dois algoritmos 